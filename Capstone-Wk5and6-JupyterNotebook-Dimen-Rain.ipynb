{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749edfe9",
   "metadata": {},
   "source": [
    "# WEEK 5 - support vector machines (SVMs), the kernel trick, and regularization for support vector machines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c15615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d2e7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2be77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "745887b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "df = pd.read_csv(\"diabetes_012_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "#2\n",
    "df_pima = pd.read_csv(\"pima_indian_diabetes_dataset.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe534e7",
   "metadata": {},
   "source": [
    "# Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c35e08",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f925e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine for Classification Dataset 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# --- 1. Prepare data ---\n",
    "X = df.drop(columns=['Diabetes_012']) \n",
    "y = df['Diabetes_012']\n",
    "\n",
    "# --- 2. Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 3. Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.02, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 4. Define SVM model + parameter grid ---\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- 5. Fit model ---\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Evaluate model ---\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "y_prob = best_svm.predict_proba(X_test)\n",
    "\n",
    "print(f\"Best Parameters: {grid_svm.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_svm.best_score_:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "# For multi-class targets, macro AUC is appropriate\n",
    "auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
    "print(f\"AUC: {auc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9111b3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'kernel': 'rbf', 'gamma': 'scale', 'C': 1}\n",
      "Best CV Accuracy: 0.668\n",
      "Test Accuracy: 0.669\n",
      "AUC: 0.740\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.67      0.79      1692\n",
      "         1.0       0.03      0.14      0.05        36\n",
      "         2.0       0.31      0.71      0.43       272\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.43      0.51      0.42      2000\n",
      "weighted avg       0.84      0.67      0.73      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine for Classification Dataset 1\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Prepare data ---\n",
    "\n",
    "df_small = df.sample(10000, random_state=42)\n",
    "X = df_small.drop(columns=['Diabetes_012'])\n",
    "y = df_small['Diabetes_012']\n",
    "\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Randomized search setup\n",
    "param_dist = {\n",
    "    'C': [0.1, 1, 10, 50],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "rand_svm = RandomizedSearchCV(\n",
    "    SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rand_svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "best_svm = rand_svm.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "y_prob = best_svm.predict_proba(X_test)\n",
    "\n",
    "print(f\"Best Parameters: {rand_svm.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {rand_svm.best_score_:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_test, y_prob, multi_class='ovr'):.3f}\\n\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182c50e",
   "metadata": {},
   "source": [
    "# Dataset 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best CV Accuracy: 0.761\n",
      "Test Accuracy: 0.740\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (154, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_score(y_test,\u001b[38;5;250m \u001b[39my_pred)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# For multi-class targets, macro AUC is appropriate\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m auc = \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43movr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClassification Report:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:686\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    684\u001b[39m     labels = np.unique(y_true)\n\u001b[32m    685\u001b[39m     y_true = label_binarize(y_true, classes=labels)[:, \u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[32m    695\u001b[39m         partial(_binary_roc_auc_score, max_fpr=max_fpr),\n\u001b[32m    696\u001b[39m         y_true,\n\u001b[32m   (...)\u001b[39m\u001b[32m    699\u001b[39m         sample_weight=sample_weight,\n\u001b[32m    700\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/metrics/_base.py:69\u001b[39m, in \u001b[36m_average_binary_score\u001b[39m\u001b[34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m     72\u001b[39m y_true = check_array(y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:433\u001b[39m, in \u001b[36m_binary_roc_auc_score\u001b[39m\u001b[34m(y_true, y_score, sample_weight, max_fpr)\u001b[39m\n\u001b[32m    424\u001b[39m     warnings.warn(\n\u001b[32m    425\u001b[39m         (\n\u001b[32m    426\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOnly one class is present in y_true. ROC AUC score \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    429\u001b[39m         UndefinedMetricWarning,\n\u001b[32m    430\u001b[39m     )\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m fpr, tpr, _ = \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr == \u001b[32m1\u001b[39m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:1163\u001b[39m, in \u001b[36mroc_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1060\u001b[39m     {\n\u001b[32m   1061\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1070\u001b[39m     y_true, y_score, *, pos_label=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1071\u001b[39m ):\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[32m   1073\u001b[39m \n\u001b[32m   1074\u001b[39m \u001b[33;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m \u001b[33;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[32m   1162\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m     fps, tps, thresholds = \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[32m   1169\u001b[39m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1174\u001b[39m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[32m   1176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) > \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/metrics/_ranking.py:867\u001b[39m, in \u001b[36m_binary_clf_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    865\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m    866\u001b[39m y_true = column_or_1d(y_true)\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m y_score = \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m assert_all_finite(y_true)\n\u001b[32m    869\u001b[39m assert_all_finite(y_score)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:1483\u001b[39m, in \u001b[36mcolumn_or_1d\u001b[39m\u001b[34m(y, dtype, warn, device)\u001b[39m\n\u001b[32m   1470\u001b[39m         warnings.warn(\n\u001b[32m   1471\u001b[39m             (\n\u001b[32m   1472\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mA column-vector y was passed when a 1d array was\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1477\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1478\u001b[39m         )\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(\n\u001b[32m   1480\u001b[39m         xp.reshape(y, (-\u001b[32m1\u001b[39m,)), order=\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, xp=xp, device=device\n\u001b[32m   1481\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1483\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1484\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m.format(shape)\n\u001b[32m   1485\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: y should be a 1d array, got an array of shape (154, 2) instead."
     ]
    }
   ],
   "source": [
    "# Support Vector Machine for Classification Dataset 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# --- 1. Prepare data ---\n",
    "X = df_pima.drop(columns=['Outcome']) \n",
    "y = df_pima['Outcome']\n",
    "\n",
    "# --- 2. Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 3. Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 4. Define SVM model + parameter grid ---\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- 5. Fit model ---\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Evaluate model ---\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "y_prob = best_svm.predict_proba(X_test)\n",
    "\n",
    "print(f\"Best Parameters: {grid_svm.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_svm.best_score_:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "# For multi-class targets, macro AUC is appropriate\n",
    "auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
    "print(f\"AUC: {auc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aea11fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best CV Accuracy: 0.761\n",
      "Test Accuracy: 0.740\n",
      "AUC: 0.825\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79       100\n",
      "           1       0.61      0.70      0.66        54\n",
      "\n",
      "    accuracy                           0.74       154\n",
      "   macro avg       0.72      0.73      0.72       154\n",
      "weighted avg       0.75      0.74      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine for Classification \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# --- 1. Prepare data ---\n",
    "X = df_pima.drop(columns=['Outcome'])   # Features\n",
    "y = df_pima['Outcome']                  # Target (binary: 0/1)\n",
    "\n",
    "# --- 2. Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 3. Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 4. Define SVM model + parameter grid ---\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- 5. Fit model ---\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Evaluate model ---\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "y_prob = best_svm.predict_proba(X_test)[:, 1]  # only the positive class probs\n",
    "\n",
    "print(f\"Best Parameters: {grid_svm.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_svm.best_score_:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC: {auc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe79515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best CV Accuracy: 0.754\n",
      "Test Accuracy: 0.755\n",
      "AUC: 0.832\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81       125\n",
      "           1       0.64      0.69      0.66        67\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.73      0.74      0.74       192\n",
      "weighted avg       0.76      0.76      0.76       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine for Classification \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# --- 1. Prepare data ---\n",
    "X = df_pima.drop(columns=['Outcome'])   # Features\n",
    "y = df_pima['Outcome']                  # Target (binary: 0/1)\n",
    "\n",
    "# --- 2. Scale features ---\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# --- 3. Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- 4. Define SVM model + parameter grid ---\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    SVC(probability=True, class_weight='balanced', random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- 5. Fit model ---\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Evaluate model ---\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "y_prob = best_svm.predict_proba(X_test)[:, 1]  # only the positive class probs\n",
    "\n",
    "print(f\"Best Parameters: {grid_svm.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {grid_svm.best_score_:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC: {auc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721bf407",
   "metadata": {},
   "source": [
    "# WEEK 6 - Decision Tree and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8ecad0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 200, 'max_features': 'log2', 'max_depth': None}\n",
      "Best CV Accuracy: 0.839\n",
      "Test Accuracy: 0.838\n",
      "AUC: 0.742\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.97      0.91      4274\n",
      "         1.0       0.00      0.00      0.00        93\n",
      "         2.0       0.47      0.17      0.25       707\n",
      "\n",
      "    accuracy                           0.84      5074\n",
      "   macro avg       0.44      0.38      0.39      5074\n",
      "weighted avg       0.79      0.84      0.80      5074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Dataset 1 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# --- 1. Prepare data ---\n",
    "X = df.drop(columns=['Diabetes_012'])   \n",
    "y = df['Diabetes_012']\n",
    "\n",
    "# --- 2. Split data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.02, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- 3. Define model + parameter distributions ---\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# --- 4. Randomized Search ---\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,              \n",
    "    cv=3,                   \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,              \n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- 5. Fit model ---\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Evaluate best model ---\n",
    "best_rf = rf_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_prob = best_rf.predict_proba(X_test)\n",
    "\n",
    "print(f\"Best Parameters: {rf_search.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {rf_search.best_score_:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "# Compute multi-class AUC if needed\n",
    "if len(np.unique(y)) > 2:\n",
    "    auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
    "else:\n",
    "    auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "print(f\"AUC: {auc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a8454d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "Best Parameters: {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "Best CV Accuracy: 0.767\n",
      "Test Accuracy: 0.760\n",
      "AUC: 0.818\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       125\n",
      "           1       0.68      0.58      0.63        67\n",
      "\n",
      "    accuracy                           0.76       192\n",
      "   macro avg       0.74      0.72      0.73       192\n",
      "weighted avg       0.75      0.76      0.76       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest - Dataset 2 \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# --- 1. Prepare data ---\n",
    "X = df_pima.drop(columns=['Outcome'])  \n",
    "y = df_pima['Outcome']\n",
    "\n",
    "# --- 2. Split data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# --- 3. Define model + parameter distributions ---\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# --- 4. Randomized Search ---\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=15,              \n",
    "    cv=5,                   \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,              \n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- 5. Fit model ---\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# --- 6. Evaluate best model ---\n",
    "best_rf = rf_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "y_prob = best_rf.predict_proba(X_test)\n",
    "\n",
    "print(f\"Best Parameters: {rf_search.best_params_}\")\n",
    "print(f\"Best CV Accuracy: {rf_search.best_score_:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "# Compute multi-class AUC if needed\n",
    "if len(np.unique(y)) > 2:\n",
    "    auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
    "else:\n",
    "    auc = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "print(f\"AUC: {auc:.3f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8f3dd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "0    500\n",
       "1    268\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pima[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4c109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
